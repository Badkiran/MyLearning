{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ebc7fd9-b051-4f8d-9731-f6500638310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import pmdarima as pmd\n",
    "\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing # SES\n",
    "from statsmodels.tsa.holtwinters import Holt # Holts Exponential Smoothing\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing \n",
    "\n",
    "from fbprophet import Prophet \n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from fbprophet.plot import plot_plotly\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import GRU\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "def adj_r2_score(r2, n, k):\n",
    "    return 1-((1-r2)*((n-1)/(n-k-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf61cecd-e612-4508-ab13-0a65d9fc2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto Regressive Model\n",
    "def AR_Model(data):\n",
    "    series = data\n",
    "    val = series.values\n",
    "    train, test = val[1:len(val)-30], val[len(val)-30:]\n",
    "    \n",
    "    #Create Model\n",
    "    start = time()\n",
    "    ar_model = AutoReg(train, lags=2).fit()\n",
    "    end = time()\n",
    "    print(\"Model fitting time:\", end-start)\n",
    "    print('Coefficients: %s' % ar_model.params)\n",
    "    \n",
    "    #Print summary of the model\n",
    "    print(ar_model.summary())\n",
    "    \n",
    "    #Get the predictions\n",
    "    predictions = ar_model.predict(start=len(train), end=len(train)+len(test)-1, dynamic=False)\n",
    "    residuals = test - predictions\n",
    "    for i in range(len(predictions)):\n",
    "        print('predicted=%f, expected=%f' % (predictions[i], test[i]))\n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "    print('Root Mean Squared Error: %.3f' %rmse)\n",
    "    mape = round(np.mean(abs(residuals/test)),4)\n",
    "    print('Mean Absolute Percentage Error:', mape)\n",
    "    \n",
    "    # plot results\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(test)\n",
    "    plt.plot(predictions)\n",
    "    \n",
    "    plt.legend(('Actual','Prediction'), fontsize=16)\n",
    "    plt.title('USD-INR Rate Change over time', fontsize=20)\n",
    "    plt.ylabel('Rate', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78edf660-ebc4-482b-8dfe-f03b9f4119ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARMA_Model(data):\n",
    "       \n",
    "    val = data.Rate.values\n",
    "    train_data, test_data =  val[1:len(val)-30], val[len(val)-30:]\n",
    "    \n",
    "    #Create Model\n",
    "    start = time()\n",
    "    arma_model = ARMA(train_data, order=(3,2)).fit()\n",
    "    end = time()\n",
    "    print(\"Model fitting time:\", end-start)\n",
    "    print('Coefficients: %s' % arma_model.params)\n",
    "    \n",
    "    #Print summary of the model\n",
    "    print(arma_model.summary())\n",
    "    \n",
    "   \n",
    "    #Get the predictions and residuals\n",
    "    predictions = arma_model.predict(start=len(train_data), end=len(train_data)+len(test_data)-1, dynamic=False)\n",
    "    residuals = test_data - predictions\n",
    "    for i in range(len(predictions)):\n",
    "        print('predicted=%f, expected=%f' % (predictions[i], test_data[i]))\n",
    "    \n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "    print('Root Mean Squared Error: %.3f' %rmse)\n",
    "    mape = round(np.mean(abs(residuals/test_data)),4)\n",
    "    print('Mean Absolute Percentage Error:', mape)\n",
    "    \n",
    "    #Plot results\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(test_data)\n",
    "    plt.plot(predictions)\n",
    "    \n",
    "    plt.legend(('Actual','Prediction'), fontsize=16)\n",
    "    plt.title('USD-INR Rate Change over time', fontsize=20)\n",
    "    plt.ylabel('Rate', fontsize=16)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc4c19e-cd49-47d7-a9dc-7d88b5075917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMA_Model(data,p,d,q):\n",
    "    \n",
    "    val = data.values\n",
    "    val = val.astype('float32')\n",
    "    train, test = val[1:len(val)-30], val[len(val)-30:]\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        arima_model = ARIMA(history, order=(p,d,q)).fit()\n",
    "        output = arima_model.forecast()\n",
    "        ypred = output[0]\n",
    "        predictions.append(ypred)\n",
    "        act = test[i]\n",
    "        history.append(act)\n",
    "        print('predicted=%f, expected=%f' % (ypred, act))\n",
    "       \n",
    "    # evaluate forecasts\n",
    "    residuals = test - predictions \n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "    print('Root Mean Squared Error: %.3f' %rmse)\n",
    "    mape = np.mean(abs(residuals/test))\n",
    "    print('Mean Absolute Percentage Error: %.3f' %mape)\n",
    "    \n",
    "    #Print summary of the model\n",
    "    print(arima_model.summary())\n",
    "    \n",
    "    # plot forecasts against actual outcomes\n",
    "    forecast=arima_model.forecast(steps=30,alpha=0.05)[0]\n",
    "    arima_model.plot_predict()\n",
    "    arima_model.plot_predict(12619,12649)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37503d80-26b8-4895-9df4-ed21ee55ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Auto_ARIMA_Model(data):\n",
    "    \n",
    "    auto_arima_model = pmd.auto_arima(data.values, start_p=1, start_q=1,\n",
    "                      test='adf',       # use adftest to find optimal 'd'\n",
    "                      max_p=5, max_q=5, # maximum p and q\n",
    "                      m=1,              # frequency of series\n",
    "                      d=None,           # let model determine 'd'\n",
    "                      seasonal=False,   # No Seasonality\n",
    "                      start_P=0, \n",
    "                      D=0, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2cf1233-909f-4987-b2da-c8cbe4f941b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simple_Exponential(data):\n",
    "    \n",
    "    val = data.values\n",
    "    train, test = val[1:len(val)-30], val[len(val)-30:]\n",
    "    ses_model = SimpleExpSmoothing(train).fit(smoothing_level=0.2)\n",
    "    pred_ses = ses_model.predict(start = 12620,end = 12649)\n",
    "    residuals = test - pred_ses \n",
    "    \n",
    "    #Calculating RMSE and MAPE\n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "    print('Root Mean Squared Error: %.3f' %rmse)\n",
    "    mape = np.mean(abs(residuals/test))\n",
    "    print('Mean Absolute Percentage Error: %.3f' %mape)                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4ece9a-3b51-42ab-876a-40c1e10f9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Holt_Winters_Linear(data):\n",
    "    \n",
    "    val = data.values\n",
    "    train, test = val[1:len(val)-30], val[len(val)-30:]\n",
    "    ses_model = Holt(train).fit(smoothing_level=0.8, smoothing_trend=0.2)\n",
    "    pred_ses = ses_model.predict(start = 12620,end = 12649)\n",
    "    residuals = test - pred_ses \n",
    "    \n",
    "    \n",
    "    #Calculating RMSE and MAPE\n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "    print('Root Mean Squared Error: %.3f' %rmse)\n",
    "    mape = np.mean(abs(residuals/test))\n",
    "    print('Mean Absolute Percentage Error: %.3f' %mape)                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e54e5d-e794-4fc4-9b17-a54ab3617aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FB_Prophet(data):\n",
    "    \n",
    "    #instantiate Prophet\n",
    "    data = data.rename(columns={'Rate': 'y', 'Date': 'ds'})\n",
    "    data['ds'] =  pd.to_datetime(data['ds'], format='%d/%m/%Y')\n",
    "    prophet_model = Prophet(daily_seasonality=True) \n",
    "    prophet_model.fit(data)\n",
    "    \n",
    "    future_data = prophet_model.make_future_dataframe(periods=30, freq = 'D')\n",
    "    \n",
    "    \n",
    "    forecast_data = prophet_model.predict(future_data)\n",
    "    forecast_data[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(5)\n",
    "    \n",
    "    fig = prophet_model.plot(forecast_data)\n",
    "    prophet_model.plot_components(forecast_data)\n",
    "    \n",
    "    final_df = pd.DataFrame(forecast_data)\n",
    "    actual_chart = go.Scatter(y=data[\"y\"], name= 'Actual')\n",
    "    predict_chart = go.Scatter(y=final_df[\"yhat\"], name= 'Predicted')\n",
    "    predict_chart_upper = go.Scatter(y=final_df[\"yhat_upper\"], name= 'Predicted Upper')\n",
    "    predict_chart_lower = go.Scatter(y=final_df[\"yhat_lower\"], name= 'Predicted Lower')\n",
    "    py.plot([actual_chart, predict_chart, predict_chart_upper, predict_chart_lower])\n",
    "    \n",
    "    print(\"Future 30 days' prediction data is:\\n\",forecast_data.head())\n",
    "    return prophet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527d8caf-bb2d-43d9-a210-a026bf454f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_Model(data):\n",
    "    data = np.array(data)\n",
    "    scaler = MinMaxScaler()\n",
    "    df = scaler.fit_transform(data)\n",
    "    \n",
    "    #Training and test sets\n",
    "    train = df[:11919]\n",
    "    test = df[11919:]\n",
    "    \n",
    "    X_train = train[:-1]\n",
    "    y_train = train[1:]\n",
    "\n",
    "    X_test = test[:-1]\n",
    "    y_test = test[1:]\n",
    "    \n",
    "    #Create model\n",
    "    K.clear_session()\n",
    "    ann_model = Sequential()\n",
    "    ann_model.add(Dense(12, input_dim=1, activation='relu'))\n",
    "    ann_model.add(Dense(1))\n",
    "    ann_model.summary()\n",
    "    \n",
    "    ann_model.compile(loss= 'mse', metrics=[tensorflow.keras.metrics.RootMeanSquaredError(name='rmse')], optimizer='adam')\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=2, verbose=1)\n",
    "    history = ann_model.fit(X_train, y_train, epochs=200, batch_size=1, verbose=1, callbacks=[early_stop], shuffle=False)\n",
    "    \n",
    "    #Prediction\n",
    "    y_pred = ann_model.predict(X_test)\n",
    "    y_pred = scaler.inverse_transform(y_pred)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    print(\"The R2 score on the Test set is:\\t{:0.3f}\".format(r2_score(y_test, y_pred)))\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(\"The Adjusted R2 score on the Test set is:\\t{:0.3f}\".format(adj_r2_score(r2_test, X_test.shape[0], X_test.shape[1])))\n",
    "    print(\"Root Mean Squared Error: %.3f\" %rmse)\n",
    "    \n",
    "    return y_test,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e8929f-e206-4b3d-a105-6559369b0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Model(data):\n",
    "    \n",
    "    data = np.array(data).reshape(-1,1)\n",
    "    scaler = MinMaxScaler()\n",
    "    df = scaler.fit_transform(data)\n",
    "    \n",
    "    #Training and test sets\n",
    "    train = df[:11919]\n",
    "    test = df[11919:]\n",
    "    \n",
    "    def get_data(data, look_back):\n",
    "        data_x, data_y = [],[]\n",
    "        for i in range(len(data)-look_back-1):\n",
    "            data_x.append(data[i:(i+look_back),0])\n",
    "            data_y.append(data[i+look_back,0])\n",
    "        return np.array(data_x) , np.array(data_y)\n",
    "\n",
    "    look_back = 1\n",
    "\n",
    "    x_train , y_train = get_data(train, look_back)\n",
    "    x_test , y_test = get_data(test,look_back)\n",
    "    \n",
    "    #Processing train and test sets for LSTM model\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1],1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1],1)\n",
    "    \n",
    "    #Defining the LSTM model\n",
    "    K.clear_session()\n",
    "    lstm_model=Sequential()\n",
    "    lstm_model.add(LSTM(100,activation='relu',input_shape=(1,x_train.shape[1]), kernel_initializer='lecun_uniform', return_sequences=False))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    #Model summary\n",
    "    lstm_model.summary()\n",
    "    \n",
    "    #Compiling\n",
    "    lstm_model.compile(optimizer='adam', loss = 'mse', metrics=[tensorflow.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "    #Training\n",
    "    lstm_model.fit(x_train,y_train, epochs = 5, batch_size=1)\n",
    "    \n",
    "    #Prediction using the trained model\n",
    "    scaler.scale_\n",
    "\n",
    "    y_pred = lstm_model.predict(x_test)\n",
    "    y_pred = scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    #Processing test shape\n",
    "    y_test = np.array(y_test).reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    print(\"The R2 score on the Test set is:\\t{:0.3f}\".format(r2_score(y_test, y_pred)))\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(\"The Adjusted R2 score on the Test set is:\\t{:0.3f}\".format(adj_r2_score(r2_test, x_test.shape[0], x_test.shape[1])))\n",
    "    print('Root Mean Squared Error: %.3f' %rmse)\n",
    "    \n",
    "    return (y_test,y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935e3b75-c0cb-42e1-8563-512e49154758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_Model(data):\n",
    "    \n",
    "    data = np.array(data).reshape(-1,1)\n",
    "    scaler = MinMaxScaler()\n",
    "    df = scaler.fit_transform(data)\n",
    "    \n",
    "    #Training and test sets\n",
    "    train = df[:11919]\n",
    "    test = df[11919:]\n",
    "      \n",
    "    def get_data(data, look_back):\n",
    "        data_x, data_y = [],[]\n",
    "        for i in range(len(data)-look_back-1):\n",
    "            data_x.append(data[i:(i+look_back),0])\n",
    "            data_y.append(data[i+look_back,0])\n",
    "        return np.array(data_x) , np.array(data_y)\n",
    "\n",
    "    look_back = 1\n",
    "\n",
    "    X_train , y_train = get_data(train, look_back)\n",
    "    X_test , y_test = get_data(test,look_back)\n",
    "    \n",
    "    #Processing train and test sets for LSTM model\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1],1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1],1)\n",
    "    \n",
    "    K.clear_session()\n",
    "    gru_model = Sequential()\n",
    "    gru_model.add(GRU(12, input_shape=(1, X_train.shape[1]), activation='linear', kernel_initializer='lecun_uniform', return_sequences=False))\n",
    "    gru_model.add(Dense(1))\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "    gru_model.compile(loss='mse', optimizer= 'adam', metrics=[tensorflow.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    gru_model.fit(X_train, y_train, epochs=100, batch_size=20, verbose=1, shuffle=False,callbacks=[early_stop])\n",
    "    gru_model.summary()\n",
    "    \n",
    "    #Prediction\n",
    "    y_pred = gru_model.predict(X_test)\n",
    "    y_pred = scaler.inverse_transform(y_pred)\n",
    "    y_test = np.array(y_test).reshape(-1,1)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "#     test_mse = tensorflow.keras.metrics.mean_squared_error(y_test, y_pred)\n",
    "#     rmse_test = np.sqrt(test_mse)\n",
    "    print(\"The R2 score on the Test set is:\\t{:0.3f}\".format(r2_score(y_test, y_pred)))\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(\"The Adjusted R2 score on the Test set is:\\t{:0.3f}\".format(adj_r2_score(r2_test, X_test.shape[0], X_test.shape[1])))\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    print(\"Root Mean Squared Error: %.3f\" %rmse)\n",
    "    \n",
    "    return y_test,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efd1e2-7a9b-4f1b-a327-1e7adb17130c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700757e4-f9d8-4182-988b-4ad4a7e9061d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9ea79-7e8a-4142-8ac6-a531348a5cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88891e3a-e9a2-48f1-8798-321837a02d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872745b3-70e1-4312-a85e-44a979577113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ced2e-d25a-4571-a5c0-57ea529667f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ad349-8c61-45df-a0e9-eafef0744980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a8ff1-5053-4782-b742-3818e46faeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703e677-9e6b-416d-909b-2ce049b69fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e69a2e-6817-4747-9415-7edd4da62e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb204f3-f1f5-4dca-9fd3-4378030eda72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fac74a-6906-480f-b87c-2172fc021ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49589491-9300-4341-b338-64e47626e3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
